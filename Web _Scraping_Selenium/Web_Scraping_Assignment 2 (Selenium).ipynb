{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing necessary libraries\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting to the driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\LENOVO\\Downloads\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1. Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening the website\n",
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering the designation, location as required in the question\n",
    "designation = driver.find_element(By.CLASS_NAME, 'suggestor-input')\n",
    "designation.send_keys('Data Analyst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = driver.find_element(By.XPATH, '/html/body/div[1]/div[7]/div/div/div[5]/div/div/div/div[1]/div/input')\n",
    "location.send_keys('Banglore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = driver.find_element(By.CLASS_NAME, \"qsbSubmit\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty lists for data\n",
    "job_title = []\n",
    "job_loc = []\n",
    "cpny_name = []\n",
    "exp_req = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = driver.find_elements(By.XPATH, '//a[@class=\"title ellipsis\"]')\n",
    "for i in title[0:10]:\n",
    "    job_title.append(i.text)\n",
    "    \n",
    "location = driver.find_elements(By.XPATH, '//span[@class=\"ellipsis fleft locWdth\"]')\n",
    "for i in location[0:10]:\n",
    "    job_loc.append(i.text)\n",
    "                   \n",
    "name = driver.find_elements(By.XPATH, '//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in name[0:10]:\n",
    "    cpny_name.append(i.text)\n",
    "    \n",
    "exp = driver.find_elements(By.XPATH, '//span[@class=\"ellipsis fleft expwdth\"]')\n",
    "for i in exp[0:10]:\n",
    "    exp_req.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "# length of arrays\n",
    "print(len(job_title), len(job_loc), len(cpny_name), len(exp_req))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dataframe\n",
    "naukri_data = pd.DataFrame({'Title':job_title, 'Location':job_loc, 'Company':cpny_name, 'Experience':exp_req})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>ANZ</td>\n",
       "      <td>6-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>ANZ</td>\n",
       "      <td>6-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst - IIT/BITS/Startups</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>AVE Promagne</td>\n",
       "      <td>1-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst - FinTech</td>\n",
       "      <td>Mumbai, Hyderabad/Secunderabad, Pune, Ahmedaba...</td>\n",
       "      <td>Primo Hiring</td>\n",
       "      <td>1-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst - FinTech</td>\n",
       "      <td>Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...</td>\n",
       "      <td>Primo Hiring</td>\n",
       "      <td>1-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Analyst - FinTech</td>\n",
       "      <td>Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...</td>\n",
       "      <td>Primo Hiring</td>\n",
       "      <td>1-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Analyst - IIT/BITS/Startups</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>AVE Promagne</td>\n",
       "      <td>1-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Temp. WFH - Noida, Pune, Gurgaon/Gurugram, Ban...</td>\n",
       "      <td>Infogain</td>\n",
       "      <td>4-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Banking Data Analyst</td>\n",
       "      <td>Hyderabad/Secunderabad, Bangalore/Bengaluru, G...</td>\n",
       "      <td>Coforge</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Dpdzero</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Title  \\\n",
       "0                      Data Analyst   \n",
       "1                      Data Analyst   \n",
       "2  Data Analyst - IIT/BITS/Startups   \n",
       "3            Data Analyst - FinTech   \n",
       "4            Data Analyst - FinTech   \n",
       "5            Data Analyst - FinTech   \n",
       "6  Data Analyst - IIT/BITS/Startups   \n",
       "7                      Data Analyst   \n",
       "8              Banking Data Analyst   \n",
       "9                      Data Analyst   \n",
       "\n",
       "                                            Location       Company Experience  \n",
       "0                                Bangalore/Bengaluru           ANZ    6-9 Yrs  \n",
       "1                                Bangalore/Bengaluru           ANZ   6-10 Yrs  \n",
       "2                                Bangalore/Bengaluru  AVE Promagne    1-5 Yrs  \n",
       "3  Mumbai, Hyderabad/Secunderabad, Pune, Ahmedaba...  Primo Hiring    1-2 Yrs  \n",
       "4  Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...  Primo Hiring    1-2 Yrs  \n",
       "5  Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...  Primo Hiring    1-2 Yrs  \n",
       "6                                Bangalore/Bengaluru  AVE Promagne    1-5 Yrs  \n",
       "7  Temp. WFH - Noida, Pune, Gurgaon/Gurugram, Ban...      Infogain    4-7 Yrs  \n",
       "8  Hyderabad/Secunderabad, Bangalore/Bengaluru, G...       Coforge   5-10 Yrs  \n",
       "9                                Bangalore/Bengaluru       Dpdzero    1-3 Yrs  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naukri_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2. Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening the website\n",
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering the designation, loation as required in the question\n",
    "designation = driver.find_element(By.CLASS_NAME, 'suggestor-input')\n",
    "designation.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = driver.find_element(By.XPATH, '/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/div[1]/div/input')\n",
    "location.send_keys('Banglore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = driver.find_element(By.CLASS_NAME, \"qsbSubmit\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty lists for data\n",
    "job_title = []\n",
    "job_loc = []\n",
    "cpny_name = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = driver.find_elements(By.XPATH, '//a[@class=\"title ellipsis\"]')\n",
    "for i in title[0:10]:\n",
    "    job_title.append(i.text)\n",
    "    \n",
    "location = driver.find_elements(By.XPATH, '//span[@class=\"ellipsis fleft locWdth\"]')\n",
    "for i in location[0:10]:\n",
    "    job_loc.append(i.text)\n",
    "                   \n",
    "name = driver.find_elements(By.XPATH, '//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in name[0:10]:\n",
    "    cpny_name.append(i.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "# length of arrays\n",
    "print(len(job_title), len(job_loc), len(cpny_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dataframe\n",
    "naukri_datasct = pd.DataFrame({'Title':job_title, 'Location': job_loc, 'Company_Name': cpny_name})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company_Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Science Specialist</td>\n",
       "      <td>Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...</td>\n",
       "      <td>Accenture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Manager, Data Solution Specialist</td>\n",
       "      <td>Mumbai, New Delhi, Bangalore/Bengaluru</td>\n",
       "      <td>Pfizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist_NLP</td>\n",
       "      <td>Mumbai, Pune, Chennai, Gurgaon/Gurugram, Banga...</td>\n",
       "      <td>Fractal Analytics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Machine Learning (AI) Architect</td>\n",
       "      <td>Kolkata, Mumbai, New Delhi, Hyderabad/Secunder...</td>\n",
       "      <td>Persistent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Permanent Opportunity For Data scientist with AWS</td>\n",
       "      <td>Hybrid - Chennai, Coimbatore, Bangalore/Bengal...</td>\n",
       "      <td>Deloitte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Infosys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>R&amp;D Specialist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Nokia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist- Bangalore</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Trigent Software</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Science Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Accenture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>IBM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0                            Data Science Specialist   \n",
       "1                  Manager, Data Solution Specialist   \n",
       "2                                 Data Scientist_NLP   \n",
       "3                    Machine Learning (AI) Architect   \n",
       "4  Permanent Opportunity For Data scientist with AWS   \n",
       "5                                     Data Scientist   \n",
       "6                                     R&D Specialist   \n",
       "7                          Data Scientist- Bangalore   \n",
       "8                               Data Science Analyst   \n",
       "9                                     Data Scientist   \n",
       "\n",
       "                                            Location       Company_Name  \n",
       "0  Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...          Accenture  \n",
       "1             Mumbai, New Delhi, Bangalore/Bengaluru             Pfizer  \n",
       "2  Mumbai, Pune, Chennai, Gurgaon/Gurugram, Banga...  Fractal Analytics  \n",
       "3  Kolkata, Mumbai, New Delhi, Hyderabad/Secunder...         Persistent  \n",
       "4  Hybrid - Chennai, Coimbatore, Bangalore/Bengal...           Deloitte  \n",
       "5                                Bangalore/Bengaluru            Infosys  \n",
       "6                                Bangalore/Bengaluru              Nokia  \n",
       "7                                Bangalore/Bengaluru   Trigent Software  \n",
       "8                                Bangalore/Bengaluru          Accenture  \n",
       "9                                Bangalore/Bengaluru                IBM  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naukri_datasct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3. In this question you have to scrape data using the filters available on the webpage. You have to use the location and salary filter. You have to scrape data for “Data Scientist” designation for first 10 job results. You have to scrape the job-title, job-location, company name, experience required. The location filter to be used is “Delhi/NCR”. The salary filter to be used is “3-6” lakhs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening the website\n",
    "driver.get('https://www.naukri.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering the designation as required in the question\n",
    "designation = driver.find_element(By.CLASS_NAME, 'suggestor-input')\n",
    "designation.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = driver.find_element(By.CLASS_NAME, \"qsbSubmit\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# location and salary using filters\n",
    "location = driver.find_element(By.XPATH, '/html/body/div[1]/div[4]/div/div/section[1]/div[2]/div[5]/div[2]/div[2]/label/p/span[1]')\n",
    "location.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "salary = driver.find_element(By.XPATH, '/html/body/div[1]/div[4]/div/div/section[1]/div[2]/div[6]/div[2]/div[2]/label/p/span[1]')\n",
    "salary.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty lists for data\n",
    "job_title = []\n",
    "job_loc = []\n",
    "cpny_name = []\n",
    "exp_req = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = driver.find_elements(By.XPATH, '//a[@class=\"title ellipsis\"]')\n",
    "for i in title[0:10]:\n",
    "    job_title.append(i.text)\n",
    "    \n",
    "location = driver.find_elements(By.XPATH, '//span[@class=\"ellipsis fleft locWdth\"]')\n",
    "for i in location[0:10]:\n",
    "    job_loc.append(i.text)\n",
    "                   \n",
    "name = driver.find_elements(By.XPATH, '//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in name[0:10]:\n",
    "    cpny_name.append(i.text)\n",
    "    \n",
    "exp = driver.find_elements(By.XPATH, '//span[@class=\"ellipsis fleft expwdth\"]')\n",
    "for i in exp[0:10]:\n",
    "    exp_req.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "# length of arrays\n",
    "print(len(job_title),len(job_loc),len(cpny_name),len(exp_req))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dataframe\n",
    "data = pd.DataFrame({'Job_Title':job_title, 'Location':job_loc, 'Company_Name': cpny_name, 'Experience':exp_req})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Manager, Data Solution Specialist</td>\n",
       "      <td>Mumbai, New Delhi, Bangalore/Bengaluru</td>\n",
       "      <td>Pfizer</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>Kolkata, Mumbai, New Delhi, Hyderabad/Secunder...</td>\n",
       "      <td>Analytos</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "      <td>Blackbuck</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Kolkata, Mumbai, New Delhi, Hyderabad/Secunder...</td>\n",
       "      <td>Analytos</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram, United States (USA), Bulgaria</td>\n",
       "      <td>Adidas</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist - II (Contract)</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Netomi</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida</td>\n",
       "      <td>Gujarat Fluorochemicals</td>\n",
       "      <td>1-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Research Scientist - Bioinformatics</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Biopeople India</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist - I</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Netomi</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>Noida</td>\n",
       "      <td>Profit By Outsourcing</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Job_Title  \\\n",
       "0    Manager, Data Solution Specialist   \n",
       "1                Junior Data Scientist   \n",
       "2                       Data Scientist   \n",
       "3                       Data Scientist   \n",
       "4                Junior Data Scientist   \n",
       "5       Data Scientist - II (Contract)   \n",
       "6                       Data Scientist   \n",
       "7  Research Scientist - Bioinformatics   \n",
       "8                   Data Scientist - I   \n",
       "9            Machine Learning Engineer   \n",
       "\n",
       "                                            Location             Company_Name  \\\n",
       "0             Mumbai, New Delhi, Bangalore/Bengaluru                   Pfizer   \n",
       "1  Kolkata, Mumbai, New Delhi, Hyderabad/Secunder...                 Analytos   \n",
       "2              Gurgaon/Gurugram, Bangalore/Bengaluru                Blackbuck   \n",
       "3  Kolkata, Mumbai, New Delhi, Hyderabad/Secunder...                 Analytos   \n",
       "4    Gurgaon/Gurugram, United States (USA), Bulgaria                   Adidas   \n",
       "5                                   Gurgaon/Gurugram                   Netomi   \n",
       "6                                              Noida  Gujarat Fluorochemicals   \n",
       "7                                   Gurgaon/Gurugram          Biopeople India   \n",
       "8                                   Gurgaon/Gurugram                   Netomi   \n",
       "9                                              Noida    Profit By Outsourcing   \n",
       "\n",
       "  Experience  \n",
       "0    3-5 Yrs  \n",
       "1    0-2 Yrs  \n",
       "2    3-7 Yrs  \n",
       "3    2-4 Yrs  \n",
       "4    1-6 Yrs  \n",
       "5    3-7 Yrs  \n",
       "6    1-2 Yrs  \n",
       "7    0-2 Yrs  \n",
       "8    3-6 Yrs  \n",
       "9    2-7 Yrs  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4. Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "4. discount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening the website\n",
    "driver.get('https://www.flipkart.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering the product name as requird\n",
    "product = driver.find_element(By.XPATH, '/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input')\n",
    "product.send_keys('sunglasses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = driver.find_element(By.CLASS_NAME, \"L0Z3Pu\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empy lists fror data\n",
    "brand = []\n",
    "description = []\n",
    "price = []\n",
    "discount = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping data across multiple pages\n",
    "start = 0\n",
    "end = 3\n",
    "for page in range(start,end):\n",
    "    bran_d = driver.find_elements(By.XPATH, '//div[@class=\"_2WkVRV\"]')\n",
    "    for i in bran_d:\n",
    "        brand.append(i.text)\n",
    "        \n",
    "    des = driver.find_elements(By.XPATH, '//a[@class=\"IRpwTa\"]')\n",
    "    for i in des:\n",
    "        description.append(i.text)\n",
    "        \n",
    "    pr = driver.find_elements(By.XPATH, '//div[@class=\"_30jeq3\"]')\n",
    "    for i in pr:\n",
    "        price.append(i.text)\n",
    "    \n",
    "    dscnt = driver.find_elements(By.XPATH, '//div[@class=\"_3Ay6Sb\"]')\n",
    "    for i in dscnt:\n",
    "        discount.append(i.text)\n",
    "        \n",
    "        \n",
    "    # to scrape data from next page\n",
    "    next_button= driver.find_element(By.XPATH, '//span[contains(text(),\"Next\")]')\n",
    "    next_button.click()\n",
    "    time.sleep(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 117 120 120\n"
     ]
    }
   ],
   "source": [
    "# length of arrays \n",
    "print(len(brand), len(description), len(price), len(discount))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating datafarame\n",
    "sunglass_df = pd.DataFrame({'Brand':brand[:100], 'Description':description[:100], 'Price':price[:100], 'Discount':discount[:100]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Labbin</td>\n",
       "      <td>Casual Sneakers ColourFul Block Shoes For Boys...</td>\n",
       "      <td>₹599</td>\n",
       "      <td>57% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Labbin</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹429</td>\n",
       "      <td>51% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kraasa</td>\n",
       "      <td>Sneakers For Women</td>\n",
       "      <td>₹299</td>\n",
       "      <td>85% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aadi</td>\n",
       "      <td>Synthetic| Lightweight| Premiun| Comfort| Summ...</td>\n",
       "      <td>₹269</td>\n",
       "      <td>83% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BIRDE</td>\n",
       "      <td>Combo Pack of 2 Casual Shoe Sneakers For Men</td>\n",
       "      <td>₹449</td>\n",
       "      <td>81% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>HOTSTYLE</td>\n",
       "      <td>Puma Wired Cage Sneakers For Men</td>\n",
       "      <td>₹499</td>\n",
       "      <td>72% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Kraasa</td>\n",
       "      <td>Combo Pack Of 2 Casual Shoes Sneakers For Men</td>\n",
       "      <td>₹299</td>\n",
       "      <td>74% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>SOLETHREADS</td>\n",
       "      <td>Spider Prime Walking/Outdoor/Sports/Sneakers/ ...</td>\n",
       "      <td>₹1,549</td>\n",
       "      <td>72% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>PUMA</td>\n",
       "      <td>Stylish Walking Partywear Sneakers Casual Shoe...</td>\n",
       "      <td>₹1,259</td>\n",
       "      <td>45% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Elevarse</td>\n",
       "      <td>UP Sneakers For Men</td>\n",
       "      <td>₹249</td>\n",
       "      <td>72% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Brand                                        Description   Price  \\\n",
       "0        Labbin  Casual Sneakers ColourFul Block Shoes For Boys...    ₹599   \n",
       "1        Labbin                                   Sneakers For Men    ₹429   \n",
       "2        Kraasa                                 Sneakers For Women    ₹299   \n",
       "3          aadi  Synthetic| Lightweight| Premiun| Comfort| Summ...    ₹269   \n",
       "4         BIRDE       Combo Pack of 2 Casual Shoe Sneakers For Men    ₹449   \n",
       "..          ...                                                ...     ...   \n",
       "95     HOTSTYLE                   Puma Wired Cage Sneakers For Men    ₹499   \n",
       "96       Kraasa      Combo Pack Of 2 Casual Shoes Sneakers For Men    ₹299   \n",
       "97  SOLETHREADS  Spider Prime Walking/Outdoor/Sports/Sneakers/ ...  ₹1,549   \n",
       "98         PUMA  Stylish Walking Partywear Sneakers Casual Shoe...  ₹1,259   \n",
       "99     Elevarse                                UP Sneakers For Men    ₹249   \n",
       "\n",
       "   Discount  \n",
       "0   57% off  \n",
       "1   51% off  \n",
       "2   85% off  \n",
       "3   83% off  \n",
       "4   81% off  \n",
       "..      ...  \n",
       "95  72% off  \n",
       "96  74% off  \n",
       "97  72% off  \n",
       "98  45% off  \n",
       "99  72% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sunglass_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5. Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link: https://www.flipkart.com/apple-iphone-11-black-64-gb/productreviews/ itm4e5041ba101fd pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&marketplace=FLIPKART You have to scrape the tick marked attributes. These are:\n",
    "1. Rating\n",
    "2. Review summary\n",
    "3. Full review\n",
    "4. You have to scrape this data for first 100 reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening the website\n",
    "driver.get('https://www.flipkart.com/apple-iphone-11-black-64-gb/productreviews/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&marketplace=FLIPKART')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #opening the website sows that the page is moved or deleted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q6. Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the search field. You have to scrape 3 attributes of each sneaker:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening the website\n",
    "driver.get('https://www.flipkart.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering product name as mentioned in the question\n",
    "product = driver.find_element(By.CLASS_NAME, '_3704LK')\n",
    "product.send_keys('sneakers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = driver.find_element(By.CLASS_NAME, 'L0Z3Pu')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty lists for data\n",
    "brand = []\n",
    "description = []\n",
    "price = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping data from multiple pages\n",
    "start = 0\n",
    "end = 3\n",
    "for page in range(start,end):\n",
    "    bran_d = driver.find_elements(By.XPATH, '//div[@class=\"_2WkVRV\"]')\n",
    "    for i in bran_d:\n",
    "        brand.append(i.text)\n",
    "        \n",
    "    des = driver.find_elements(By.XPATH, '//a[@class=\"IRpwTa\"]')\n",
    "    for i in des:\n",
    "        description.append(i.text)\n",
    "        \n",
    "    pr = driver.find_elements(By.XPATH, '//div[@class=\"_30jeq3\"]')\n",
    "    for i in pr:\n",
    "        price.append(i.text)\n",
    "        \n",
    "    next_button = driver.find_element(By.XPATH, \"//span[contains(text(),'Next')]\")\n",
    "    next_button.click()\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 116 120\n"
     ]
    }
   ],
   "source": [
    "# length of array\n",
    "print(len(brand), len(description), len(price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dataframe\n",
    "sneaker_df = pd.DataFrame({'Brand_Name':brand[:100], \"Product_Description\":description[:100], \"Price\":price[:100]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand_Name</th>\n",
       "      <th>Product_Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Labbin</td>\n",
       "      <td>Casual Sneakers ColourFul Block Shoes For Boys...</td>\n",
       "      <td>₹599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Labbin</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kraasa</td>\n",
       "      <td>Sneakers For Women</td>\n",
       "      <td>₹299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aadi</td>\n",
       "      <td>Synthetic| Lightweight| Premiun| Comfort| Summ...</td>\n",
       "      <td>₹269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BIRDE</td>\n",
       "      <td>Combo Pack of 2 Casual Shoe Sneakers For Men</td>\n",
       "      <td>₹449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>HOTSTYLE</td>\n",
       "      <td>Puma Wired Cage Sneakers For Men</td>\n",
       "      <td>₹499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Kraasa</td>\n",
       "      <td>Combo Pack Of 2 Casual Shoes Sneakers For Men</td>\n",
       "      <td>₹299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Footox</td>\n",
       "      <td>Spider Prime Walking/Outdoor/Sports/Sneakers/ ...</td>\n",
       "      <td>₹499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>PUMA</td>\n",
       "      <td>Stylish Walking Partywear Sneakers Casual Shoe...</td>\n",
       "      <td>₹1,259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Elevarse</td>\n",
       "      <td>UP Sneakers For Men</td>\n",
       "      <td>₹249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Brand_Name                                Product_Description   Price\n",
       "0      Labbin  Casual Sneakers ColourFul Block Shoes For Boys...    ₹599\n",
       "1      Labbin                                   Sneakers For Men    ₹429\n",
       "2      Kraasa                                 Sneakers For Women    ₹299\n",
       "3        aadi  Synthetic| Lightweight| Premiun| Comfort| Summ...    ₹269\n",
       "4       BIRDE       Combo Pack of 2 Casual Shoe Sneakers For Men    ₹449\n",
       "..        ...                                                ...     ...\n",
       "95   HOTSTYLE                   Puma Wired Cage Sneakers For Men    ₹499\n",
       "96     Kraasa      Combo Pack Of 2 Casual Shoes Sneakers For Men    ₹299\n",
       "97     Footox  Spider Prime Walking/Outdoor/Sports/Sneakers/ ...    ₹499\n",
       "98       PUMA  Stylish Walking Partywear Sneakers Casual Shoe...  ₹1,259\n",
       "99   Elevarse                                UP Sneakers For Men    ₹249\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sneaker_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q7. Go to webpage https://www.amazon.in/ Enter “Laptop” in the search field and then click the search icon. Then set CPU Type filter to “Intel Core i7”. After setting the filters scrape first 10 laptops data. You have to scrape 3 attributes for each laptop:\n",
    "1. Title\n",
    "2. Ratings\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening the wbsite\n",
    "driver.get(\"https://www.amazon.in/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering product details\n",
    "product = driver.find_element(By.XPATH, '/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[2]/div[1]/input')\n",
    "product.send_keys('Laptop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = driver.find_element(By.XPATH, '/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[3]/div/span/input')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting filters\n",
    "cpu = driver.find_element(By.XPATH, '/html/body/div[1]/div[2]/div[1]/div[2]/div/div[3]/span/div[1]/div/div/div[6]/ul[7]/span[11]/li/span/a/span')\n",
    "cpu.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty lists for data\n",
    "title = []\n",
    "price = []\n",
    "rating = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttl = driver.find_elements(By.XPATH, '//span[@class=\"a-size-medium a-color-base a-text-normal\"]')\n",
    "for i in ttl:\n",
    "    title.append(i.text)\n",
    "    \n",
    "pr = driver.find_elements(By.XPATH, '//span[@class=\"a-price-whole\"]')\n",
    "for i in pr:\n",
    "    price.append(i.text)\n",
    "\n",
    "rate = driver.find_elements(By.XPATH, '//a[@class=\"a-popover-trigger a-declarative\"]')\n",
    "for i in rate:\n",
    "    rating.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 32 26\n"
     ]
    }
   ],
   "source": [
    "# length of arrays\n",
    "print(len(title), len(price), len(rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dataframe\n",
    "laptop = pd.DataFrame({'Title':title[:10], 'Price':price[:10], \"Ratings\":rating[:10]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Price</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ASUS TUF Gaming F15 (2022), 15.6\"(39.62 cms) F...</td>\n",
       "      <td>94,989</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Acer Predator Helios Neo 16 Gaming Laptop 13th...</td>\n",
       "      <td>1,29,990</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lenovo ThinkPad E14 Intel Core i7 12th Gen 14\"...</td>\n",
       "      <td>98,990</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HP Pavilion Plus, 12th Gen Intel Core i7 16GB ...</td>\n",
       "      <td>88,990</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Samsung Galaxy Book2 (NP750) Intel 12th Gen co...</td>\n",
       "      <td>79,990</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HP Victus Gaming Latest 12th Gen Intel Core i7...</td>\n",
       "      <td>79,990</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HP Envy x360 12th Gen Intel Core i7-13.3 inch(...</td>\n",
       "      <td>1,02,990</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MSI Modern 14, Intel 13th Gen. i7-1355U, 36CM ...</td>\n",
       "      <td>74,990</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lenovo ThinkBook 15 Intel 12th Gen Core i7 15....</td>\n",
       "      <td>85,490</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LG Gram16 Intel EVO-[12th Gen Core i7/Win11/16...</td>\n",
       "      <td>99,990</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title     Price Ratings\n",
       "0  ASUS TUF Gaming F15 (2022), 15.6\"(39.62 cms) F...    94,989        \n",
       "1  Acer Predator Helios Neo 16 Gaming Laptop 13th...  1,29,990        \n",
       "2  Lenovo ThinkPad E14 Intel Core i7 12th Gen 14\"...    98,990        \n",
       "3  HP Pavilion Plus, 12th Gen Intel Core i7 16GB ...    88,990        \n",
       "4  Samsung Galaxy Book2 (NP750) Intel 12th Gen co...    79,990        \n",
       "5  HP Victus Gaming Latest 12th Gen Intel Core i7...    79,990        \n",
       "6  HP Envy x360 12th Gen Intel Core i7-13.3 inch(...  1,02,990        \n",
       "7  MSI Modern 14, Intel 13th Gen. i7-1355U, 36CM ...    74,990        \n",
       "8  Lenovo ThinkBook 15 Intel 12th Gen Core i7 15....    85,490        \n",
       "9  LG Gram16 Intel EVO-[12th Gen Core i7/Win11/16...    99,990        "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "laptop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q8. Write a python program to scrape data for Top 1000 Quotes of All Time.The above task will be done in following steps:\n",
    "1. First get the webpage https://www.azquotes.com/\n",
    "2. Click on Top Quotes\n",
    "3. Than scrap a) Quote b) Author c) Type Of Quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening the website\n",
    "driver.get(' https://www.azquotes.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top quotes from website\n",
    "top_quote = driver.find_element(By.XPATH, '/html/body/div[1]/div[1]/div[1]/div/div[3]/ul/li[5]/a')\n",
    "top_quote.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty list for data\n",
    "quote = []\n",
    "author = []\n",
    "type_quote = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping data from multiple pages\n",
    "start = 0\n",
    "end = 10\n",
    "for page in range(start,end):\n",
    "    quo = driver.find_elements(By.XPATH, '//a[@class=\"title\"]')\n",
    "    for i in quo:\n",
    "        quote.append(i.text)\n",
    "        \n",
    "    athr = driver.find_elements(By.XPATH, '//div[@class=\"author\"]')\n",
    "    for i in athr:\n",
    "        author.append(i.text)\n",
    "    \n",
    "    typ_ = driver.find_elements(By.XPATH, '//div[@class=\"tags\"]')\n",
    "    for i in typ_:\n",
    "        type_quote.append(i.text)\n",
    "        \n",
    "    next_button = driver.find_element(By.CLASS_NAME,'next')\n",
    "    next_button.click()\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 1000 1000\n"
     ]
    }
   ],
   "source": [
    "# length of array\n",
    "print(len(quote),len(author),len(type_quote))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quote</th>\n",
       "      <th>Author</th>\n",
       "      <th>Types</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The essence of strategy is choosing what not t...</td>\n",
       "      <td>Michael Porter</td>\n",
       "      <td>Essence, Deep Thought, Transcendentalism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>One cannot and must not try to erase the past ...</td>\n",
       "      <td>Golda Meir</td>\n",
       "      <td>Inspiration, Past, Trying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Patriotism means to stand by the country. It d...</td>\n",
       "      <td>Theodore Roosevelt</td>\n",
       "      <td>Country, Peace, War</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Death is something inevitable. When a man has ...</td>\n",
       "      <td>Nelson Mandela</td>\n",
       "      <td>Inspirational, Motivational, Death</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You have to love a nation that celebrates its ...</td>\n",
       "      <td>Erma Bombeck</td>\n",
       "      <td>4th Of July, Food, Patriotic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Regret for the things we did can be tempered b...</td>\n",
       "      <td>Sydney J. Harris</td>\n",
       "      <td>Love, Inspirational, Motivational</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>America... just a nation of two hundred millio...</td>\n",
       "      <td>Hunter S. Thompson</td>\n",
       "      <td>Gun, Two, Qualms About</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>For every disciplined effort there is a multip...</td>\n",
       "      <td>Jim Rohn</td>\n",
       "      <td>Inspirational, Greatness, Best Effort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>The spiritual journey is individual, highly pe...</td>\n",
       "      <td>Ram Dass</td>\n",
       "      <td>Spiritual, Truth, Yoga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>The mind is not a vessel to be filled but a fi...</td>\n",
       "      <td>Plutarch</td>\n",
       "      <td>Inspirational, Leadership, Education</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Quote              Author  \\\n",
       "0    The essence of strategy is choosing what not t...      Michael Porter   \n",
       "1    One cannot and must not try to erase the past ...          Golda Meir   \n",
       "2    Patriotism means to stand by the country. It d...  Theodore Roosevelt   \n",
       "3    Death is something inevitable. When a man has ...      Nelson Mandela   \n",
       "4    You have to love a nation that celebrates its ...        Erma Bombeck   \n",
       "..                                                 ...                 ...   \n",
       "995  Regret for the things we did can be tempered b...    Sydney J. Harris   \n",
       "996  America... just a nation of two hundred millio...  Hunter S. Thompson   \n",
       "997  For every disciplined effort there is a multip...            Jim Rohn   \n",
       "998  The spiritual journey is individual, highly pe...            Ram Dass   \n",
       "999  The mind is not a vessel to be filled but a fi...            Plutarch   \n",
       "\n",
       "                                        Types  \n",
       "0    Essence, Deep Thought, Transcendentalism  \n",
       "1                   Inspiration, Past, Trying  \n",
       "2                         Country, Peace, War  \n",
       "3          Inspirational, Motivational, Death  \n",
       "4                4th Of July, Food, Patriotic  \n",
       "..                                        ...  \n",
       "995         Love, Inspirational, Motivational  \n",
       "996                    Gun, Two, Qualms About  \n",
       "997     Inspirational, Greatness, Best Effort  \n",
       "998                    Spiritual, Truth, Yoga  \n",
       "999      Inspirational, Leadership, Education  \n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating dataframe\n",
    "quote_data = pd.DataFrame({'Quote':quote, 'Author':author, 'Types':type_quote})\n",
    "quote_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q9. Write a python program to display list of respected former Prime Ministers of India(i.e. Name, Born-Dead, Term of office, Remarks) from https://www.jagranjosh.com/. This task will be done in following steps:\n",
    "1. First get the webpage https://www.jagranjosh.com/\n",
    "2. Then You have to click on the GK option\n",
    "3. Then click on the List of all Prime Ministers of India\n",
    "4. Then scrap the mentioned data and make the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening the website\n",
    "driver.get(' https://www.jagranjosh.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting the gk option\n",
    "gk = driver.find_element(By.XPATH, '/html/body/div/div[1]/div/div[1]/div/div[5]/div/div[1]/header/div[3]/ul/li[3]/a')\n",
    "gk.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting the list of prime ministers\n",
    "pm = driver.find_element(By.XPATH, '/html/body/div[1]/div/div/div[2]/div/div[10]/div/div/ul/li[2]/a')\n",
    "pm.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q10. Write a python program to display list of 50 Most expensive cars in the world (i.e. Car name and Price) from https://www.motor1.com/. This task will be done in following steps:\n",
    "1. First get the webpage https://www.motor1.com/\n",
    "2. Then You have to click on the List option from Dropdown menu on left side.\n",
    "3. Then click on 50 most expensive cars in the world..\n",
    "4. Then scrap the mentioned data and make the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening the website\n",
    "driver.get(\"https://www.motor1.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the dropdown menu\n",
    "dropdown = driver.find_element(By.CLASS_NAME, 'm1-hamburger-button')\n",
    "dropdown.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "toggle = driver.find_element(By.XPATH, '/html/body/div[4]/div[1]/div[3]/ul/li[5]/button')\n",
    "toggle.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_ = driver.find_element(By.XPATH, '/html/body/div[4]/div[1]/div[3]/ul/li[6]/ul/li[1]/a')\n",
    "list_.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of 50 fastest cars\n",
    "fast_50 = driver.find_element(By.XPATH, '//a[contains(text(),\"50 Fastest\")]')\n",
    "fast_50.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creaing empty lists for data\n",
    "name = []\n",
    "speed =[]\n",
    "\n",
    "# finding name and price \n",
    "nam_e = driver.find_elements(By.XPATH, '//h3[@class=\"subheader\"]')\n",
    "for i in nam_e:\n",
    "    name.append(i.text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Fastest Cars In The World'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = driver.find_elements(By.TAG_NAME,'strong')\n",
    "for i in pr:\n",
    "    speed.append(i.text.split(':')[1].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating data frame\n",
    "fast50 = pd.DataFrame({'Car_Name':name, 'Speed':speed})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Car_Name</th>\n",
       "      <th>Speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ferrari LaFerrari</td>\n",
       "      <td>217 MPH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>McLaren P1</td>\n",
       "      <td>217 MPH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mercedes-AMG One</td>\n",
       "      <td>217 MPH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lamborghini Sian FKP 37</td>\n",
       "      <td>217 MPH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lotus Evija</td>\n",
       "      <td>217 MPH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Bugatti Chiron Pur Sport</td>\n",
       "      <td>218 MPH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ferrari Enzo</td>\n",
       "      <td>218.7 MPH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Pininfarina Battista</td>\n",
       "      <td>218 MPH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Aston Martin One-77</td>\n",
       "      <td>220 MPH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Lambo Aventador LP780-4 Ultimae Coupe</td>\n",
       "      <td>220 MPH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Pagani Huayra Codalunga</td>\n",
       "      <td>220 MPH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>De Tomaso P72</td>\n",
       "      <td>221 MPH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Lamborghini Countach</td>\n",
       "      <td>221 MPH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Lamborghini Veneno</td>\n",
       "      <td>221 MPH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Gordon Murray T.50</td>\n",
       "      <td>230 MPH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Pagani Zonda R</td>\n",
       "      <td>233 MPH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Pagani Huayra BC Pacchetto Tempesta</td>\n",
       "      <td>236 MPH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Bugatti Divo</td>\n",
       "      <td>236 MPH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Pagani Huayra</td>\n",
       "      <td>238 MPH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Bugatti Centodieci</td>\n",
       "      <td>240 MPH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Deus Vayanne</td>\n",
       "      <td>248 MPH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>McLaren F1</td>\n",
       "      <td>240.1 MPH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Koenigsegg CCR</td>\n",
       "      <td>241.0 MPH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Koenigsegg Gemera</td>\n",
       "      <td>249 MPH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Aspark Owl</td>\n",
       "      <td>249 MPH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Koenigsegg Agera R</td>\n",
       "      <td>249 MPH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Aston Martin Valkyrie</td>\n",
       "      <td>250 MPH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Tesla Roadster</td>\n",
       "      <td>250 MPH+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>W Motors Fenyr SuperSport</td>\n",
       "      <td>250 MPH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>McLaren Speedtail</td>\n",
       "      <td>250.4 MPH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Bugatti Veyron</td>\n",
       "      <td>253.8 MPH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>SSC Ultimate Aero</td>\n",
       "      <td>257.4 MPH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Rimac Nevera</td>\n",
       "      <td>258 MPH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Bugatti La Voiture Noire</td>\n",
       "      <td>260 MPH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Bugatti Mistral</td>\n",
       "      <td>261 MPH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Zenvo TSR-GT</td>\n",
       "      <td>263 MPH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Bugatti Veyron 16.4 Super Sport</td>\n",
       "      <td>267.9 MPH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Hennessey Venom GT</td>\n",
       "      <td>270.5 MPH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Bugatti Chiron Super Sport</td>\n",
       "      <td>273 MPH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Koenigsegg One:1</td>\n",
       "      <td>273 MPH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Koenigsegg Agera RS</td>\n",
       "      <td>277.9 MPH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Czinger 21C</td>\n",
       "      <td>281 MPH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>SSC Tuatara</td>\n",
       "      <td>295.0 MPH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Hennessey Venom F5 Roadster</td>\n",
       "      <td>300 MPH+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Koenigsegg CC850</td>\n",
       "      <td>300 MPH+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Bugatti Chiron Super Sport 300+</td>\n",
       "      <td>304.8 MPH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>SP Automotive Chaos</td>\n",
       "      <td>310 MPH+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Hennessey Venom F5</td>\n",
       "      <td>311 MPH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Bugatti Bolide</td>\n",
       "      <td>311 MPH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Koenigsegg Jesko Absolut</td>\n",
       "      <td>330 MPH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Car_Name      Speed\n",
       "0                       Ferrari LaFerrari    217 MPH\n",
       "1                              McLaren P1    217 MPH\n",
       "2                        Mercedes-AMG One    217 MPH\n",
       "3                 Lamborghini Sian FKP 37    217 MPH\n",
       "4                             Lotus Evija    217 MPH\n",
       "5                Bugatti Chiron Pur Sport    218 MPH\n",
       "6                            Ferrari Enzo  218.7 MPH\n",
       "7                    Pininfarina Battista    218 MPH\n",
       "8                     Aston Martin One-77    220 MPH\n",
       "9   Lambo Aventador LP780-4 Ultimae Coupe    220 MPH\n",
       "10                Pagani Huayra Codalunga    220 MPH\n",
       "11                          De Tomaso P72    221 MPH\n",
       "12                   Lamborghini Countach    221 MPH\n",
       "13                     Lamborghini Veneno    221 MPH\n",
       "14                     Gordon Murray T.50    230 MPH\n",
       "15                         Pagani Zonda R    233 MPH\n",
       "16    Pagani Huayra BC Pacchetto Tempesta    236 MPH\n",
       "17                           Bugatti Divo    236 MPH\n",
       "18                          Pagani Huayra    238 MPH\n",
       "19                     Bugatti Centodieci    240 MPH\n",
       "20                           Deus Vayanne    248 MPH\n",
       "21                             McLaren F1  240.1 MPH\n",
       "22                         Koenigsegg CCR  241.0 MPH\n",
       "23                      Koenigsegg Gemera    249 MPH\n",
       "24                             Aspark Owl    249 MPH\n",
       "25                     Koenigsegg Agera R    249 MPH\n",
       "26                  Aston Martin Valkyrie    250 MPH\n",
       "27                         Tesla Roadster   250 MPH+\n",
       "28              W Motors Fenyr SuperSport    250 MPH\n",
       "29                      McLaren Speedtail  250.4 MPH\n",
       "30                         Bugatti Veyron  253.8 MPH\n",
       "31                      SSC Ultimate Aero  257.4 MPH\n",
       "32                           Rimac Nevera    258 MPH\n",
       "33               Bugatti La Voiture Noire    260 MPH\n",
       "34                        Bugatti Mistral    261 MPH\n",
       "35                           Zenvo TSR-GT    263 MPH\n",
       "36        Bugatti Veyron 16.4 Super Sport  267.9 MPH\n",
       "37                     Hennessey Venom GT  270.5 MPH\n",
       "38             Bugatti Chiron Super Sport    273 MPH\n",
       "39                       Koenigsegg One:1    273 MPH\n",
       "40                    Koenigsegg Agera RS  277.9 MPH\n",
       "41                            Czinger 21C    281 MPH\n",
       "42                            SSC Tuatara  295.0 MPH\n",
       "43            Hennessey Venom F5 Roadster   300 MPH+\n",
       "44                       Koenigsegg CC850   300 MPH+\n",
       "45        Bugatti Chiron Super Sport 300+  304.8 MPH\n",
       "46                    SP Automotive Chaos   310 MPH+\n",
       "47                     Hennessey Venom F5    311 MPH\n",
       "48                         Bugatti Bolide    311 MPH\n",
       "49               Koenigsegg Jesko Absolut    330 MPH"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fast50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
